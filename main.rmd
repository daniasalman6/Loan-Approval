---
title: "Data Science Project - Loan Approval"
author: "Alex Biuckians, Armin Soroosh, Dania Salman, Kaipu Liu"
output:
  html_document:
    code_folding: hide
    number_sections: false
    theme: journal
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results="hide", message = F)
#knitr::opts_chunk$set(warning = F, message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

## Loading the Dataset
```{r read_dataset, echo=TRUE}
# reading dataset
loan_df <- data.frame(read.csv("loan_approval_dataset.csv"))
```

```{r explore_dataset, echo=TRUE}
# exploring dataset
str(loan_df)
```
The dataset has **4269 observations** with **13 variables**

## Data Cleaning & Summary

### subsetting data and converting categorical variables to factor
Removing loan_id column since it only serves as a unique identifier and does not contribute to the analysis. Furthermore, converting several numeric variables into factors, as they represent categorical information rather than continuous numerical values.
```{r data_cleaning, echo=TRUE}
loan_df <- subset(loan_df, select = -c(loan_id))

# converting the numeric variables to factor variables
loan_df$no_of_dependents = as.factor(loan_df$no_of_dependents)
loan_df$education = as.factor(loan_df$education)
loan_df$self_employed = as.factor(loan_df$self_employed)
loan_df$loan_status = as.factor(loan_df$loan_status)
str(loan_df)
```
After conversion, the dataset contains four categorical variables:

- **no_of_dependents:** Number of dependents the applicant has (`6` categories: `0`, `1`, `2`, `3`, `4`, `5`)

- **education:** Applicant’s level of education (`2` categories: `Graduate`, `Not Graduate`)

- **self_employed:** Whether the applicant is self-employed (`2` categories: `Yes`, `No`)

- **loan_status:** Loan approval status — this is the target variable (`2` categories: `Approved`, `Rejected`)

### Finding NA values
```{r, echo=TRUE}
sum(is.na(loan_df))
```
There are no NA values in the data set

### Summary of the dataset
```{r echo=TRUE}
summary(loan_df)
```
Overall, the dataset appears well-structured and balanced. **Categorical variables** such as `education`, `self_employment`, and `loan_status` show nearly **even distributions** across their categories. Most **numerical variables** fall within reasonable ranges, with average loan terms around `11 years` and CIBIL scores centered near `600`, both indicating realistic applicant profiles. However, some financial variables like income, loan amount, and asset values show wide variation and possible outliers. In particular, the presence of negative values in `residential_assets_value` points to potential data quality issues that will need correction before exploration or testing.

### Cleaning up negative values
Checking the number of rows that have negative values for `residential_assets_value` column
```{r echo=TRUE}
sum(loan_df$residential_assets_value < 0)
```
There are `28` entries with negative values.

### Removing entries with negative values
```{r echo=TRUE}
loan_df <- loan_df[loan_df$residential_assets_value >= 0, ]
str(loan_df)
summary(loan_df)
```
After filtering out the rows with negative values, the dataset now has `4,241 observations`. The distributions across all variables look almost identical to before, showing that this cleaning step didn’t affect the data overall.

## Exploratory Data Analysis

### Does education level affect loan approval?
```{r Q1, echo=TRUE}

```

### Do people with higher asset values tend to get approved more often?
```{r Q2, echo=TRUE}

```

### Is there a significant difference in average income between approved and rejected applicants?
```{r Q3, echo=TRUE}
# Group by loan approval status and extract their annual income data
approved_income <- loan_df$income_annum[loan_df$loan_status == " Approved"]
rejected_income <- loan_df$income_annum[loan_df$loan_status == " Rejected"]
# Calculate each group's mean annual income
mean_approved <- mean(approved_income, na.rm = TRUE)
mean_rejected <- mean(rejected_income, na.rm = TRUE)
cat("Mean annual income of Approved group:", mean_approved, "\n")
cat("Mean annual income of Rejected group:", mean_rejected, "\n")

# Conduct hypothesis testing
t_test_result <- t.test(approved_income, rejected_income)
print("t-test result：")
print(t_test_result)
# Draw the histogram
hist(approved_income, 
     col = "lightgreen",
     main = "The distribution of annual income", 
     xlab = "Annual income", 
     ylab = "Frequency",
     breaks = 30)
hist(rejected_income, 
     col = "red", 
     breaks = 30,
     add = TRUE)
legend("topright", 
       legend = c("Approved", "Rejected"), 
       fill = c("lightgreen", "red")) 

```
The average income of the approved group is 5,025,904, and that of the rejected group is 5,113,825, with a difference of approximately 87,921. Then I did the hypothesis testing to do advanced judgment.

H0: There is no significant difference in the average annual income between two groups.
H1: There is a significant difference in the average annual income between two groups.

According to the result of t-test:
t-value: -1, indicating that the difference between the two group means is not prominent compared to the sample variation.
p-value: 0.3 which is much larger than the significance level of 0.05, indicating that the different is non-significant.
95% confidence interval: [-260,821, 84,978]. The interval contains 0, indicating that the mean difference between the two groups may be 0.
Finally, I drew the histogram chart, the distribution of each group's annual income is uniform. Also enhanced the conclusion.

All above suggests that income alone may not be a strong predictor of loan approval in this dataset.



### Is there a correlation between applicant's annual income and loan amount requested?
```{r Q4, echo=TRUE}
annual_income <- loan_df$income_annum
loan_amount <- loan_df$loan_amount

# Check whether normal distribution
shapiro_income <- shapiro.test(annual_income)
shapiro_loan <- shapiro.test(loan_amount)
cat("p-value of annual income：", shapiro_income$p.value, "\n")
cat("p-value of loan amount：", shapiro_loan$p.value, "\n")
# Choose the correlation coefficient
if (shapiro_income$p.value > 0.05 & shapiro_loan$p.value > 0.05) {
  cor_result <- cor.test(annual_income, loan_amount, method = "pearson")
  cat("Pearson result：\n")
} else {
  cor_result <- cor.test(annual_income, loan_amount, method = "spearman")
  cat("Spearman reslut：\n")
}
print(cor_result)

# Draw the plot
plot(
  x = annual_income,
  y = loan_amount,
  main = "Annual Income vs. Loan Amount Requested",
  xlab = "Annual Income",
  ylab = "Loan Amount Requested",
  pch = 16,
  col = "lightblue",
  cex = 0.8
)
# Add the regression line
abline(lm(loan_amount ~ annual_income), col = "red", lwd = 2)
legend("topleft", 
       legend = "regression line", 
       col = "red", 
       lty = 1, 
       lwd = 2)




```
I checked whether the data of annual income and loan amount is follow the normal distribution and choose the Spearman  correlation coefficient according to the result.
The rho is 0.941 which is close to 1, indicating that there is a very strong positive monotonic correlation between the annual income and loan amount exist and the p-value is far less than 0.05 also showed this correlation is very significant in statistic.
Then according to the plot chart, it's very clear that the loan amount shows an obvious upward trend from the bottom left to the top right as annual income increases, and the red regression line further strengthens the visual evidence of this linear association, indicating a strong positive correlation tendency between the two.
In short, this analysis clearly draws the conclusion that "annual income is a key factor affecting the loan application amount, and there is a strong positive correlation between the two."

### Is there a significant difference in average CIBIL scores between approved and rejected applicants?
```{r Q5, echo=TRUE}

```

### For rejected loans, is there a significant difference in the mean CIBIL score between applicants with shorter loan term loans (<=10 years) versus longer term loans(>10 years)?
```{r Q6, echo=TRUE}

```

### Is there a correlation between the CIBIL Score and the Loan Term among those whose loans are approved?  
```{r Q7, echo=TRUE}

```

### Does self-employment status affect loan approval?
```{r Q8, echo=TRUE}

```

### Does the number of dependents affect approval of loans?
```{r Q9, echo=TRUE}

```

### Does requested loan term affect approval?
```{r Q10, echo=TRUE}

```



<<<<<<< Updated upstream
=======
sil <- silhouette(km$cluster, dist(data_kmeans_scaled))
mean(sil[, 3])  
```

The silhouette score of 0.423 indicates that the two borrower clusters are reasonably well-separated, meaning the clustering has captured meaningful differences in income, assets, loan amount, and CIBIL score. While the groups are not perfectly distinct, the separation is strong enough to provide useful insights into different borrower profiles.

#### Creating cluster profiles

Attaching cluster labels to both the scaled and original datasets, then calculating the average unscaled feature values for each cluster to create interpretable cluster profiles.

```{r echo=TRUE}
# df_scaled already contains cluster labels
df_scaled <- as.data.frame(data_kmeans_scaled)
df_scaled$cluster <- factor(km$cluster)

# -----------------------
# 1. Add cluster labels to ORIGINAL data
# -----------------------
df_unscaled <- data_kmeans      # original (unscaled) data
df_unscaled$cluster <- factor(km$cluster)

# -----------------------
# 2. Compute cluster profiles using unscaled values
# -----------------------
cluster_profiles_unscaled <- df_unscaled %>%
  group_by(cluster) %>%
  summarise(
    loan_amount = mean(loan_amount),
    cibil_score = mean(cibil_score),
    income_annum = mean(income_annum),
    combined_asset_value = mean(combined_asset_value)
  )

print(cluster_profiles_unscaled)
```

#### Cluster interpretation
- **Cluster 1: High-value borrowers:** This cluster represents financially strong borrowers who request very large loans and possess significant asset holdings and high annual income. Despite having slightly lower CIBIL scores on average, their high net worth and strong cash flow make them lower risk from a collateral perspective.

- **Cluster 2: Moderate-value borrowers:** This cluster consists of moderate-income, moderate-asset borrowers who apply for smaller loans and have slightly better credit scores. Their financial profile is less substantial than Cluster 1, but their stronger CIBIL scores might indicate better repayment discipline.

These differences suggest that the clustering effectively separates borrowers based on financial strength and borrowing patterns.

#### SVM classification to validate cluster separability

```{r echo=TRUE}
library(caret)
library(e1071)

# Combine original features with cluster labels
cluster_data <- df_unscaled   # df_unscaled already includes: loan_amount, combined_asset_value, cibil_score, income_annum, cluster

set.seed(123)

# 80/20 train-test split (stratified by cluster)
index <- createDataPartition(cluster_data$cluster, p = 0.8, list = FALSE)
train_data <- cluster_data[index, ]
test_data  <- cluster_data[-index, ]

table(cluster_data$cluster)    # Check class balance

svm_model <- svm(
  cluster ~ loan_amount + combined_asset_value + cibil_score + income_annum,
  data = train_data,
  kernel = "radial",
  class.weights = table(cluster_data$cluster) / nrow(cluster_data)
)

predictions <- predict(svm_model, newdata = test_data)

confusion_matrix <- table(predictions, test_data$cluster)
print(confusion_matrix)

accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", accuracy))
```
We trained a Support Vector Machine to classify observations into the two k-means clusters. The model achieved an accuracy of 99.65%, with only 3 misclassifications out of 847 test observations. The confusion matrix shows very strong separation between the clusters, indicating that the cluster structure found by k-means is highly stable and predictable from the input features. This validates that the clusters represent genuinely distinct segments rather than random partitions.

#### Calinski-Harabasz Index(Cluster internal assessment)
```{r}
library(fpc)
# calculate CH index
ch <- calinhara(data_kmeans_scaled, km$cluster, cn = 2)
cat("Calinski-Harabasz Index:", ch, "\n")

# compare CH index under different k values
ch_values <- sapply(1:10, function(k) {
  km_temp <- kmeans(data_kmeans_scaled, k, nstart = 20)
  ch <- calinhara(data_kmeans_scaled, km$cluster, cn = k)
})
plot(1:10, ch_values, type = "b", xlab = "k", ylab = "CH Index", main = "CH Index under different K values")
```
Calculating the CH index for this k-means model. The principle is to calculate the ratio of the variance between clusters to the variance within clusters. The larger the value, the greater the difference between clusters and the more compact the clusters within.
The result obtained here is 4531, which is a quite large value, indicating that the clustering result is quite good.
Then I compared the CH index under different k values. As can be seen from the graph, when k = 2, the CH index is the largest, which once again confirms the same result as the elbow principle - when the number of clusters is 2, it is the most suitable.

### Bootstrap sampling verification(Cluster stability assessment)
```{r}
library(fpc)
set.seed(123)
stab <- clusterboot(data_kmeans_scaled, 
                    clustermethod = kmeansCBI, 
                    k = 2, 
                    runs = 100, 
                    seed = 123)
print(stab$bootmean)
print(stab$bootbrd)  
```
In the bootstrap sampling verification, this model achieved excellent results with bootmean = 0.994, 0.995 and bootbrd = 0, 0. This indicates that this K-means model has extremely strong clustering stability.
The value of bootmean is extremely close to 1, indicating that the two clusters can be consistently reproduced in over 99% of the samples, and there is almost no "false clusters caused by sampling randomness". 
"bootbrd" represents the ambiguity of the cluster boundary. The smaller the value, the clearer the cluster boundary. This model has reached the theoretical minimum value. The boundaries of the two clusters are almost completely clear. These two clusters are genuine structures in the data, and not the result of arbitrary division by the clustering algorithm.

For a better understanding, this is the result of PCA dimensionality reduction visualization.
```{r}
cluster_factor <- factor(km$cluster, levels = c(1, 2), labels = c("Cluster 1", "Cluster 2"))
library(FactoMineR)
library(factoextra)
library(ggplot2)
pca <- PCA(data_kmeans_scaled, graph = FALSE)
fviz_pca_ind(
  pca, 
  geom.ind = "point", 
  col.ind = cluster_factor,
  palette = c("#2E9FDF", "#E7B800"),
  legend.title = "Cluster",
  title = "PCA Visualization Result",
  xlab = "PC1", 
  ylab = "PC2",
  repel = TRUE
) + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```
We can see two clusters can be observed to be almost completely separated along the PC1 axis (with only a very small amount of overlap near PC1 = 0)

### Parallel Coordinate Plot(Visual verification)
```{r}
library(GGally)
plot_data <- cbind(data_kmeans_scaled, cluster = factor(km$cluster))
ggparcoord(plot_data, 
           columns = 1:4, 
           groupColumn = "cluster",
           scale = "globalminmax",
           alphaLines = 0.5) +
  labs(title = "Cluster distribution of each feature") +
  theme_minimal()
```
This parallel coordinate plot illustrates the distribution differences of the two clusters in terms of the four standardized features.
Cluster 1 has dark tones, while Cluster 2 has light tones.
Firstly, the dark and light color areas in the figure hardly overlap, indicating that the characteristic trajectories of the two clusters are significantly different.
Secondly, this graph visually verifies the characteristics of the two clusters previously separated. The lines of the high-value cluster are concentrated in the area of "high loan/asset/income and low CIBIL score", while the lines of the low-value cluster are concentrated in the area of "low loan/asset/income and high CIBIL score".


### About t-test and ANOVA test
I think t-tests and ANOVA tests are of little significance because K-means is already used to group variables. If these testing methods are employed, the results will definitely be significant.




## References

Do 1, 2, or 3 predictors (cibil credit score, annual income, and loan amount) have a better indicator on loan approval.

Null Hypothesis: H0 = All three models are equally effective indicators, or the simplest model is the best since it factors in adding more variables (AIC1≈AIC2≈AIC3)  
Alternative Hypothesis: HA= the model with the minimum AIC is the best indicator, demonstrating a statistically superior balance of fit and model simplicity compared to the other two.

First let us run Chi-squared tests to determine dependence of variables.

```{r}
chisq.test(loan_df$loan_status, loan_df$cibil_score)
chisq.test(loan_df$loan_status, loan_df$income_annum)
chisq.test(loan_df$loan_status, loan_df$loan_amount)
```

These tests see if two variables are significantly associated with each other. These Chi-squared test on the three variable, CIBIL credit score, annual income, and loan amount, indicate that the CIBIL credit score was the only variable with a  p-value lower than the standard significance of .05, the p-value being 2.2e-16. This means we reject the null hypothesis that that CIBIL score and loan approval are independent and have no relationship and that the CIBIL credit score is dependent on the loan status.  We fail to reject the null hypotheses for annual income and loan amount compared to loan status, as both p-values are greater than .05, the annual income p-value being .6853, and the loan amount p-value being .8637. This means that the annual income and loan approval are independent and that loan amount and loan approval are independent.

```{r}
library(regclass)
library(ResourceSelection)

LogitM1 <- glm(loan_status ~ cibil_score, data = loan_df, family = "binomial")
summary(LogitM1)

#evaluation step - confidence interval
confint.default(LogitM1)

#evaluation step - confusion matrix
confusion_matrix(LogitM1)

#evaluation step - Hosmer and Lemeshow
hoslem.test(as.numeric(loan_df$loan_status) - 1, fitted(LogitM1))

#evaluation step - McFadden R^2
null_tLogit <- glm(loan_status ~ 1, data = loan_df, family = "binomial")
mcFadden = 1 - logLik(LogitM1) / logLik(null_tLogit)
cat("McFadden R-squared: ", format(mcFadden, digits=3), "\n")
```

```{r}
LogitM2 <- glm(loan_status ~ cibil_score + income_annum, data = loan_df, family = "binomial")
summary(LogitM2)

#evaluation step - confidence interval
confint.default(LogitM2)

#evaluation step - confusion matrix
confusion_matrix(LogitM2)

#evaluation step - Hosmer and Lemeshow
hoslem.test(as.numeric(loan_df$loan_status) - 1, fitted(LogitM2))

#evaluation step - McFadden R^2
null_tLogit <- glm(loan_status ~ 1, data = loan_df, family = "binomial")
mcFadden = 1 - logLik(LogitM2) / logLik(null_tLogit)
cat("McFadden R-squared: ", format(mcFadden, digits=3), "\n")
```

```{r}
LogitM3 <- glm(loan_status ~ cibil_score + income_annum + loan_amount, data = loan_df, family = "binomial")
summary(LogitM3)

#evaluation step - confidence interval
confint.default(LogitM3)

#evaluation step - confusion matrix
confusion_matrix(LogitM3)

#evaluation step - Hosmer and Lemeshow
hoslem.test(as.numeric(loan_df$loan_status) - 1, fitted(LogitM3))

#evaluation step - McFadden R^2
null_tLogit <- glm(loan_status ~ 1, data = loan_df, family = "binomial")
mcFadden = 1 - logLik(LogitM3) / logLik(null_tLogit)
cat("McFadden R-squared: ", format(mcFadden, digits=3), "\n")
```

All three models are highly significant to affect on loan approval, as they all have p-values less than the standard level of statistical significance of .05. The first model shows only the CIBIL score. Since it is highly significant with an estimate of -.021534, this means that the as the CIBIL score increases, the odds of the loan being rejected, decreases. The McFadden R^2 of .62 shows that the CIBIL scores explains a large portion of the variance of loan status. The AIC of 2155.6 indicates that this model is the middle value, meaning it The addition of annual income was added to the second model and failed to provide a unique statistically significant contribution, as evidenced by a lack of change in the valuation step. The annual income coefficient is not statistically significant at .706 meaning that the Annual Income adds very little information that is new. The AIC is 2157.4, which is the worst model of the three. The minimal gain is not worth adding the parameter.  The third model that incorporated all three predictors, that being CIBIL credit score, annual income, and loan amount, had the highest R-squared value of 0.63 compared to the other two models' value of 0.623. All three coefficients are now all highly significant, as the CIBIL score has a coefficient at 2e<-116, annual income is p=2.11e-13, and loan amount is p=1.01e-14. The third model also had an accuracy of 92.1%, a slight increase from the first and second model's accuracy of 91.8%. The third model also has the lowest AIC score at 2096.9.

To answer the question that is posed, we reject the null hypothesis and state that Model3 with the three predictors, which include CIBIL score, annual income, and loan amount, is the best predictor and it outweighs the penalty of adding more parameters. Since M3 has the highest McFadden R^2, it shows that Model3 accounts for a slightly greater proportion of variability in loan approval status than the other models.
>>>>>>> Stashed changes

